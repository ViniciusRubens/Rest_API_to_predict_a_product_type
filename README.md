# Construction and Deploy for a Machine Learning Model to Logistic Sector using API

### About the project
**Smart Logistics API** is a Machine Learning solution designed to optimize the handling of sensitive electronic products. In the high-demand logistics sector, efficiency and safety are paramount. This project automates the identification of package contents, ensuring that high-value electronics receive the appropriate care during transport and storage.

### Problem
Logistics centers struggle with the rapid and accurate identification of package contents due to generic or unclear external packaging. This lack of visibility often leads to:
* **Improper handling** of sensitive electronics.
* **Increased operational costs** due to damaged goods.
* **Customer dissatisfaction**.

### Solution
We developed a predictive Machine Learning model exposed via a lightweight **Flask API**. By analyzing only two input variablesâ€”**Package Weight** and **Packaging Type**â€”the system accurately classifies the electronic product inside. This allows logistics staff to instantly determine the correct handling protocol via a simple API request, without opening the box.

### Tech stack
* **Language:** Python
* **API Framework:** Flask
* **Machine Learning:** cuML Random Forest Classifier
* **Data Processing:** Pandas, NumPy

---

### Data Source & Pipeline

The model relies on a **synthetic dataset** generated by `create_synthetic_dataset.py`. To simulate real-world logistics challenges, this script introduces statistical noise and occasional labeling errors, ensuring the model is robust against imperfect input data.

#### Reproduction Workflow
To regenerate the data and retrain the model from scratch, follow this pipeline:

1.  **Data Generation:** Run `create_synthetic_dataset.py`.
    * *Action:* Move the generated CSV file into the `dataset/` folder.
2.  **Preprocessing:** Run `build_dataset.py`.
    * *Action:* This script creates the train/test splits and fits the necessary data encoders.
3.  **Training:** Run `random_forest.py`.
    * *Action:* This will train the algorithm and serialize the model artifacts (weights) required by the API.

### Model

```bash
{
    "best_parameters": {
        "max_depth": 6,
        "min_samples_leaf": 2,
        "n_estimators": 100
    },
    "test_metrics": {
        "accuracy": 0.903,
        "confusion_matrix": [
            [442, 50],
            [47, 461]
        ]
    }
}
```

---

## Getting Started

Follow these instructions to set up a local copy of the project.

### Prerequisites

In this project I used `conda` for environment management.
* Ensure you have [Anaconda](https://www.anaconda.com/products/distribution) or [Miniconda](https://docs.conda.io/en/latest/miniconda.html) installed.

### Installation

1.  **Clone the repository** (or download the files to a local folder).
    ```bash
    git clone [https://github.com/ViniciusRubens/Rest_API_to_predict_a_product_type](https://github.com/ViniciusRubens/Rest_API_to_predict_a_product_type)
    cd your-repository-name
    ```

2.  **Create a new conda environment** (this example uses `project_env` as the name):
    ```bash
    conda create --name project_env python=3.12
    ```

3.  **Activate the new environment:**
    ```bash
    conda activate project_env
    ```

4.  **Install pip** into the environment:
    ```bash
    conda install pip
    ```

5.  **Install the required dependencies** from `requirements.txt`:
    ```bash
    pip install -r requirements.txt
    ```

---

## Usage


With your `project_env` environment still active, run the application using the following command to start WSGI server:

```bash
./start_api.sh
```

In another terminal:

```bash
python client.py
```

This will reports something like that after put the entries:

```bash
--- ðŸš€ API Prediction Client ---
Connecting to: http://localhost:5000/vinicius_rubens/api/predict
Type 'sair' or 'exit' at any prompt to quit.

Enter package weight in grams (e.g., 300.0) or 'sair' to exit: 250
Enter package size ('Small Package' or 'Large Package') or 'sair' to exit: Large Package

Sending request to http://localhost:5000/vinicius_rubens/api/predict...

--- âœ… API Success Response ---
{
  "input_received": {
    "package_size": "Large Package",
    "package_weight_gr": "250"
  },
  "predicted_product_type": "Tablet"
}
----------------------------------------
```

To close API you need to run:

```bash
./stop_api.sh
```

You can use WSGI from Gunicorn in terminal, try:

```bash
gunicorn --workers 4 --bind 0.0.0.0:5000 run:app
```
---

## How it Works (Step-by-Step)

When you run `client.py` and input the package details, here is the exact lifecycle of that request within the system:

1.  **Client Request:**
    The client script packages your inputs (e.g., `250g`, `Large Package`) into a JSON payload and sends a `POST` request to the `/predict` endpoint.

2.  **Server Reception:**
    The Flask application (running via Gunicorn) receives the request. It immediately validates if the required fields (`package_weight_gr`, `package_size`) are present.

3.  **Data Preprocessing (The Critical Step):**
    Before reaching the model, the raw data is transformed using the **encoders** saved during the training pipeline (`build_dataset.py`):
    * The `package_size` (Categorical) is converted into a numerical format using the loaded *LabelEncoder*.

4.  **Inference:**
    The **Random Forest Classifier** (loaded from memory) receives this feature vector to arrive at a classification.

5.  **Post-Processing:**
    The system maps the predicted class ID back to its human-readable string using the target encoder (e.g., `1` -> `"Tablet"`).

6.  **Response:**
    The API constructs a JSON response containing the original input (for verification) and the final prediction, sending it back to your terminal in milliseconds.

---

## Cleanup

To deactivate and remove the conda environment (optional).

1.  **Deactivate the environment:**
    ```bash
    conda deactivate
    ```

2.  **Remove the environment (optional):**
    ```bash
    conda remove --name project_env --all
    ```

---

## License

Distributed under the MIT License. See `LICENSE` file for more information.


